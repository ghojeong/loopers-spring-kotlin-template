# Collect, Stack, Zip

서비스에서 다양한 가치를 창출하기 위해 대량의 데이터를 모으고, 쌓고, 압착해야 합니다. 데이터의 규모가 커지면, 점점 이런 작업들을 웹 애플리케이션 내에서 처리하는 것에 대한 부하가 가파르게 높아집니다.  
그래서 우리는 마지막으로 `spring-batch` 애플리케이션을 만들어 볼 거예요. 이를 기반으로 일간 랭킹 뿐 아닌 주간, 월간 랭킹 또한 집계를 활용해 만들어 봅시다.

## Summary

지난 라운드에서 Kafka Consumer 와 Redis ZSET 을 활용해 메세지를 압착해 처리량을 높이는 테크닉, 특정 점수 기준의 정렬 SET 활용 방법을 학습하고 실시간으로 갱신되는 일단위 랭킹을 만들어보았습니다.  
이번 라운드에서는 Spring Batch 를 이용해 주간, 월간 랭킹을 구현합니다. **Batch** 는 일간 집계를 기반으로 주간, 월간 집계를 만들어내고 **API** 는 일간 랭킹 뿐 아니라 주간, 월간 랭킹도 제공합니다.

## Keywords

- Spring Batch (Job / Step / Chunk / Tasklet)
- ItemReader / ItemProcessor / ItemWriter
- Materialized View (사전 집계)
- 실시간 처리 vs 배치 처리

## Bacth System

### **Batch Processing** 이 왜 필요할까요?

- **대규모 집계**
  - 수억 건 데이터에 대한 합산, 평균, 통계는 실시간으로 처리하기엔 비용이 너무 크다.
  - e.g. "지난 한 달간 상품별 매출 TOP 100" → 매 요청마다 계산하면 DB/Redis 부하로 서비스 전체가 흔들림
- **운영 리포트/통계**
  - 경영진 보고용, BI 툴, 월간 정산 등은 수 초 단위의 실시간성이 필요하지 않음
  - 정확성과 대량처리가 더 중요 → 하루 한 번 배치로 계산해도 충분
- **데이터 정제 및 적재**
  - 로그 수집 → 정제 → DW 적재 같은 과정은 실시간보다는 일정 주기 단위로 몰아서 처리하는 게 효율적

### 실무에서 자주 보는 배치 시나리오

- **주문 정산**
  - 주문/결제/환불 데이터를 모아 매일 새벽 3시 정산 테이블 생성.
  - PG사 매출/정산 금액 검증도 함께.
- **랭킹/통계 적재**
  - 일간/주간/월간 인기 상품 집계
  - 카테고리별 판매량 통계
- **데이터 정리/청소**
  - 만료된 쿠폰 삭제, 오래된 로그 제거, 캐시 초기화
- **데이터 웨어하우스(DW) 적재**
  - 서비스 DB → DW(BigQuery, Redshift 등) 로 적재 후 분석

### 실시간 vs 배치 트레이드오프

| 항목 | 실시간 처리 | 배치 처리 |
| --- | --- | --- |
| 장점 | 즉각 반영 → UX 좋음 | 대규모 집계, 비용 효율적 |
| 단점 | 인프라 복잡, 멱등성 관리 필요 | 지연 발생, 실시간성 부족 |
| 적합 | 좋아요 수, 실시간 랭킹 | 월간 리포트, 대시보드, BI |
| 초점 | **신속성** | **정확성 & 효율성** |

---

## Spring Batch

### **기본 구성 요소**

- **Job** : 배치 실행 단위 (예: “일간 주문 통계 Job”)
- **Step** : Job 을 구성하는 세부 단계

### 배치 처리 모델

#### Chunk-Oriented Processing

- 데이터 읽기 (Reader) → 가공 (Processor) → 저장 (Writer)
- 청크 단위로 트랜잭션이 관리됨 → 안정적 대량 처리

```java
@Bean
public Step orderStatsStep(
  JobRepository jobRepository,
  PlatformTransactionManager txManager,
  ItemReader<Order> reader, 
  ItemProcessor<Order, OrderStat> processor,
  ItemWriter<OrderStat> writer
) {
    return new StepBuilder("orderStatsStep", jobRepository)
        .<Order, OrderStat>chunk(1000, txManager)
        .reader(reader)
        .processor(processor)
        .writer(writer)
        .build();
}
```

- 장점
  - 대규모 집계/정산/데이터 변환에 적합
  - 트랜잭션 단위 조절 가능

---

#### Tasklet

- Step = 하나의 작업(Task) 실행
- 반복 구조 없음, 단발성 작업에 적합

```java
@Bean
public Step cleanupStep(
	JobRepository jobRepository,
	PlatformTransactionManager txManager
) {
    return new StepBuilder("cleanupStep", jobRepository)
      .tasklet((contribution, chunkContext) -> {
          orderRepository.deleteOldOrders(); // 만료 주문 삭제
          return RepeatStatus.FINISHED;
      }, txManager)
      .build();
}
```

- 장점
  - 간단한 SQL 실행, 파일 이동, 캐시 초기화 등에 적합
  - Reader/Processor/Writer 필요 없는 작업에 깔끔

일반적으로 **구현의 용이성** 등을 이유로 Tasklet 내에서 로직 상으로 Chunk Oriented Processing 을 구현하기도 합니다.

---

### Materialized View

이전에 **Join 한계를 극복하기 위한 조회 전용 구조**로서 `Materialized View` 에 대해 언급되었던 적이 있었습니다.  
이번엔 **복잡한 집계 쿼리를 극복하기 위한 조회 전용 구조**로서 `Materialized View` 를 만나볼 거예요.

- **복잡한 집계 쿼리를 미리 계산해둔 조회 전용 구조**
- MySQL 은 MV 기능이 별도로 없으므로 보통 **별도 테이블 + 배치 적재** 방식 사용
- 주기적으로 대규모 데이터 (각 상품의 일별 일간 집계) 를 주기적으로 집계해 활용

```sql
CREATE TABLE product_metrics_weekly ( // 주간 상품 이벤트 집계
  product_id BIGINT PRIMARY KEY,
  like_count INT,
  order_count INT,
  view_count INT,
  yearMonthWeek VARCHAR, // 예시입니다.
  updated_at DATETIME
);

CREATE TABLE product_metrics_monthly ( // 월간 상품 이벤트 집계
  product_id BIGINT PRIMARY KEY,
  like_count INT,
  order_count INT,
  view_count INT,
  yearMonth VARCHAR, // 예시입니다.
  updated_at DATETIME
);
```

---

### 운영 관점에서의 배치 전략

- **스케줄링** : Spring Scheduler, Quartz 혹은 인프라 (Cron + K8s)
- **재실행 전략** : 실패 시 부분 롤백 vs 전체 재실행
- **병렬 Step** : 여러 Step 을 동시에 실행해 성능 향상
- **모니터링** : 실행 로그, 실패 알림, 처리 건수 추적
